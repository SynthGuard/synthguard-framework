{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a modified LAGO pipeline for demostrating a concept. User can set privacy and utility goals based on their use case. For simplicity purposes the target parameters can range from 0-1 and actually the privacy metric is just NewRowSynthesis metric and the utility is just the SPECKS metric. The library module generates set number of datasets and chooses the closest dataset to desired targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_package = ['synthguard'] # replace with synthguard git repo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp import dsl\n",
    "from kfp.compiler import Compiler\n",
    "from kfp import components as comp\n",
    "from typing import NamedTuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import synthguard.helper_functions as sd\n",
    "from synthguard.input_handler import InputHandler\n",
    "\n",
    "\n",
    "# from input_handler import InputHandler\n",
    "\n",
    "INPUT_PATH = './../../../code/synthetic_data_tool/datasets/tabular/cyber/LAGO/elamislubade_taotlused.csv'\n",
    "\n",
    "# input handler\n",
    "inputHandler = InputHandler()\n",
    "inputHandler.load_data_csv(\"https://opendata.smit.ee/ppa/csv/elamislubade_taotlused.csv\", 1000)\n",
    "# input_handler.load_data_csv(file_path=INPUT_PATH)\n",
    "input_data = inputHandler.data\n",
    "input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFP Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_real_data(output_csv: comp.OutputPath('csv')):\n",
    "\timport synthguard.helper_functions as sd\n",
    "\tfrom synthguard.input_handler import InputHandler\n",
    "\tprint('Started loading data')\n",
    "\t#Component logic\n",
    "\tinputHandler = InputHandler()\n",
    "\tinputHandler.load_data_csv(\"https://opendata.smit.ee/ppa/csv/elamislubade_taotlused.csv\", 1000)\n",
    "\tprint('Finished loading data')\n",
    "\tinput_data = inputHandler.data\n",
    "\tsd.save_to_csv(input_data, output_csv)\n",
    "\n",
    "# Compiling funtion into a KFP component\n",
    "input_component = comp.create_component_from_func(func = input_real_data, base_image = 'python:3.10', packages_to_install = sg_package)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import synthguard.helper_functions as sd\n",
    "from synthguard.data_preprocessor import DataPreprocessor\n",
    "\n",
    "dataPreprocessor = DataPreprocessor(data = input_data)\n",
    "processed_data, metadata = dataPreprocessor.preprocess_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFP Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(input_csv: comp.InputPath('csv'), output_json: comp.OutputPath('json')):\n",
    "    import synthguard.helper_functions as sd\n",
    "    from synthguard.data_preprocessor import DataPreprocessor\n",
    "\n",
    "    #Component logic\n",
    "    input_data = sd.load_data_csv(input_csv)\n",
    "    dataPreprocessor = DataPreprocessor(data = input_data)\n",
    "\n",
    "    processed_data, metadata = dataPreprocessor.preprocess_data()\n",
    "    sd.save_metadata(metadata, output_json)\n",
    "\n",
    "# Compiling funtion into a KFP component\n",
    "preprocess_component = comp.create_component_from_func(func = preprocess, base_image = 'python:3.10', packages_to_install = sg_package)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Data Generation using CopulaGANSynthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from synthetic_data_generator import SyntheticDataGenerator\n",
    "import synthguard.helper_functions as sd\n",
    "from synthguard.synthetic_data_generator import SyntheticDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "OutputCSV = 'elamislubade_taotlused_synthetic.csv'\n",
    "output_path = 'synthetic_datasets/tabular/cyber/LAGO/'\n",
    "if OutputCSV:\n",
    "    # Create the output path if it does not exist\n",
    "    import os\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    OutputCSV = output_path + OutputCSV\n",
    "    \n",
    "N_Rows = 1000\n",
    "EPOCHS = 1\n",
    "Locales = 'ee_ET'\n",
    "synthetic_data_type = 'realistic'\n",
    "\n",
    "syntheticDataGenerator = SyntheticDataGenerator(locales=Locales, n_rows=N_Rows, method=synthetic_data_type, output_csv=OutputCSV)\n",
    "generated_data = syntheticDataGenerator.generate_synthetic_data(metadata = metadata, processed_data = processed_data, Nepochs=EPOCHS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFP Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthtetic_data_generation(target_utility:float, target_privacy:float, input_csv: comp.InputPath('csv'), input_json:comp.InputPath('json'), output_csv: comp.OutputPath('csv')):\n",
    "    import synthguard.helper_functions as sd\n",
    "    from synthguard.synthetic_data_generator import SyntheticDataGenerator\n",
    "\n",
    "    # Parameters\n",
    "    n_datasets = 10\n",
    "    n_rows = 100\n",
    "    epochs = 64\n",
    "    locales = 'ee_ET'\n",
    "    synthetic_data_type = 'realistic'\n",
    "\n",
    "    #Component logic\n",
    "    metadata = sd.load_metadata(input_json)\n",
    "    real_data = sd.load_data_csv(input_csv)\n",
    "\n",
    "    syntheticDataGenerator = SyntheticDataGenerator(output_csv = output_csv, n_rows = n_rows, method= synthetic_data_type, locales=locales)\n",
    "    generated_data = syntheticDataGenerator.find_closest_dataset(target_utility = target_utility, target_privacy = target_privacy, metadata = metadata, real_data = real_data, n_epochs=epochs, n_datasets=n_datasets)\n",
    "\n",
    "# Compiling funtion into a KFP component\n",
    "generation_component = comp.create_component_from_func(func = synthtetic_data_generation, base_image = 'python:3.10', packages_to_install = sg_package)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnostic Report\n",
    "\n",
    "* The Diagnostic Report runs some basic checks for data format and validity. Run this to ensure that you have created valid synthetic data.\n",
    "    * **Data Validity:** Basic validity checks for each of the columns. For example, continuous values in the synthetic data must adhere to the min/max range in the real data\n",
    "    * **Structure:** Checks to ensure the real and synthetic data have the same column names and types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diagnostic_report_generator import DiagnosticEvaluator\n",
    "\n",
    "diagnosticReportGenerator = DiagnosticEvaluator(real_data = processed_data, synthetic_data = generated_data, metadata = metadata, method=synthetic_data_type)\n",
    "diagnosticReportGenerator.run_diagnostic_realistic()\n",
    "diagnosticReportGenerator.plot_diagnostic_report_realistic(output_path = output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFP Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnostic_report(input_synth_csv: comp.InputPath('csv'), input_real_csv: comp.InputPath('csv'), input_json:comp.InputPath('json'), output_html: comp.OutputPath('html')) -> NamedTuple('VisualizationOutput', [('mlpipeline_ui_metadata', 'UI_metadata')]):\n",
    "    import synthguard.helper_functions as sd\n",
    "    import json\n",
    "\n",
    "    with open(output_html, \"w\") as f:\n",
    "        f.write(\"<html><body>\")  # Start the HTML document\n",
    "\n",
    "    #Component logic\n",
    "    from synthguard.diagnostic_report_generator import DiagnosticEvaluator    \n",
    "    # from diagnostic_report_generator import DiagnosticEvaluator\n",
    "    real_data = sd.load_data_csv(input_real_csv)\n",
    "    synthetic_data = sd.load_data_csv(input_synth_csv)\n",
    "    metadata = sd.load_metadata(input_json)\n",
    "    synthetic_data_type = 'realistic'\n",
    "    \n",
    "    # diagnosticReportGenerator = DiagnosticEvaluator(real_data = real_data, synthetic_data = generated_data, metadata = metadata, method=synthetic_data_type)\n",
    "    # diagnosticReportGenerator.run_diagnostic_realistic()\n",
    "    # diagnosticReportGenerator.plot_diagnostic_report_realistic(output_path = output_path)\n",
    "\n",
    "    diagnosticReportGenerator = DiagnosticEvaluator(real_data = real_data, synthetic_data = synthetic_data, metadata = metadata, method=synthetic_data_type)\n",
    "    diagnosticReportGenerator.run_diagnostic_realistic()\n",
    "    diagnosticReportGenerator.plot_diagnostic_report_realistic()\n",
    "    diagnosticReportGenerator.save_plot_to_html(output_html)\n",
    "\n",
    "    # Read the HTML content for UI metadata\n",
    "    with open(output_html, 'r') as file:\n",
    "        html_content = file.read()\n",
    "\n",
    "    metadata = {\n",
    "        'outputs': [{\n",
    "            'type': 'web-app',\n",
    "            'storage': 'inline',\n",
    "            'source': html_content,\n",
    "        }]\n",
    "    }\n",
    "\n",
    "    from collections import namedtuple\n",
    "    visualization_output = namedtuple('VisualizationOutput', ['mlpipeline_ui_metadata'])\n",
    "    return visualization_output(json.dumps(metadata))\n",
    "\n",
    "# Compiling funtion into a KFP component\n",
    "diagnostic_component = comp.create_component_from_func(func = diagnostic_report, base_image = 'python:3.10',\n",
    "                                                       packages_to_install = sg_package)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Report\n",
    "* The Utiltiy Report checks for statistical similarity between the real and the synthetic data. Use this to discover which patterns the synthetic data has captured from the real data.\n",
    "    * **Column Shapes:** The statistical similarity between the real and synthetic data for single columns of data. This is often called the marginal distribution of each column.\n",
    "    * **Column Pair Trends:** The statistical similarity between the real and synthetic data for pairs of columns. This is often called the correlation or bivariate distributions of the columns.\n",
    "* Population Metrics:\n",
    "    * **Observed pMSE:** \n",
    "    * **Standard pMSE:**\n",
    "    * **Observed-Null pMSE Ratio:**\n",
    "    * **Kolmogorov-Smirnov Distance (SPECKS):**\n",
    "\n",
    "| Metric                         | Description                                                                                      | Range                    | Interpretation                                                                                                        | Better Values                              |\n",
    "|---------------------------------|--------------------------------------------------------------------------------------------------|--------------------------|----------------------------------------------------------------------------------------------------------------------|--------------------------------------------|\n",
    "| **Observed pMSE**               | The observed **propensity score mean-squared error** between real and synthetic data.              | $0 \\leq \\text{pMSE} < \\infty$ | Measures how closely the synthetic data mimics the real data in terms of propensity scores.                         | **Lower** values are better. A value of 0 means perfect matching. |\n",
    "| **Standard pMSE**               | The **null-standardized pMSE**, which compares the observed pMSE to a distribution of pMSEs from a null model (e.g., random permutations). | $0 \\leq \\text{Standard pMSE} < \\infty$ | Indicates how much the observed pMSE deviates from the null distribution. Lower values suggest that the synthetic data closely mimics real data compared to random variations. | **Lower** values are better. |\n",
    "| **Observed-Null pMSE Ratio**    | The ratio of observed pMSE to the standard pMSE. A ratio of 1 indicates that the observed pMSE is close to the mean of the null distribution. | $0 \\leq \\text{Ratio} < \\infty$ | The higher the ratio, the more the observed pMSE deviates from the null distribution. A ratio of 1 is ideal, indicating that the observed pMSE is not significantly different from the null model. | **Closer to 1** is better. A higher ratio indicates greater deviation from the null model. |\n",
    "| **Kolmogorov-Smirnov Distance (SPECKS)** | The Kolmogorov-Smirnov distance measures the **difference** between the **Cumulative Distribution Functions (CDFs)** of the real and synthetic data’s propensity scores. | $0 \\leq \\text{KS distance} \\leq 1$ | Measures how closely the real and synthetic data’s propensity score distributions align. A value of 0 means perfect match, and 1 means they are completely different. | **Lower** values are better, with 0 indicating a perfect match. |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from quality_report_generator import DataQualityEvaluator\n",
    "\n",
    "dataQualityEvaluator = DataQualityEvaluator(real_data = processed_data, synthetic_data = generated_data, metadata = metadata, method=synthetic_data_type)\n",
    "dataQualityEvaluator.evaluate_quality()\n",
    "dataQualityEvaluator.plot_quality_report_realistic(output_path = output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFP Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_report(input_synth_csv: comp.InputPath('csv'), input_real_csv: comp.InputPath('csv'), input_json:comp.InputPath('json'), output_html: comp.OutputPath('html')) -> NamedTuple('VisualizationOutput', [('mlpipeline_ui_metadata', 'UI_metadata')]):\n",
    "    import synthguard.helper_functions as sd\n",
    "    import json\n",
    "\n",
    "    with open(output_html, \"w\") as f:\n",
    "        f.write(\"<html><body>\")  # Start the HTML document\n",
    "\n",
    "    #Component logic\n",
    "    from synthguard.quality_report_generator import DataQualityEvaluator\n",
    "    real_data = sd.load_data_csv(input_real_csv)\n",
    "    synthetic_data = sd.load_data_csv(input_synth_csv)\n",
    "    metadata = sd.load_metadata(input_json)\n",
    "    synthetic_data_type = 'realistic'\n",
    "    \n",
    "        \n",
    "    dataQualityEvaluator = DataQualityEvaluator(real_data = real_data, synthetic_data = synthetic_data, metadata = metadata, method=synthetic_data_type)\n",
    "    dataQualityEvaluator.evaluate_quality()\n",
    "    dataQualityEvaluator.plot_quality_report_realistic()\n",
    "    dataQualityEvaluator.save_plot_to_html(output_html)\n",
    "\n",
    "    # Read the HTML content for UI metadata\n",
    "    with open(output_html, 'r') as file:\n",
    "        html_content = file.read()\n",
    "\n",
    "    metadata = {\n",
    "        'outputs': [{\n",
    "            'type': 'web-app',\n",
    "            'storage': 'inline',\n",
    "            'source': html_content,\n",
    "        }]\n",
    "    }\n",
    "\n",
    "    from collections import namedtuple\n",
    "    visualization_output = namedtuple('VisualizationOutput', ['mlpipeline_ui_metadata'])\n",
    "    return visualization_output(json.dumps(metadata))\n",
    "\n",
    "# Compiling funtion into a KFP component\n",
    "utility_component = comp.create_component_from_func(func = quality_report, base_image = 'python:3.10', \n",
    "                                                    packages_to_install = sg_package)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privacy Report\n",
    "\n",
    "\n",
    "| **Privacy Metric**            | **Description**                                                                                                                                                               | **Method**                                                                                             | **Use Cases**                                                                                         | **Pros**                                                                                             | **Cons**                                                                                             | **Range of Values**                  | **Preferred Range**             |\n",
    "|-------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------|--------------------------------------|---------------------------------|\n",
    "| **CategoricalCAP**            | Measures the risk of disclosing sensitive information through an inference attack. We assume that some values in the real data are public knowledge. An attacker is combining this with synthetic data to make guesses about other real values that are sensitive. This metric describes how difficult it is for an attacker to correctly guess the sensitive information using an algorithm called Correct Attribution Probability (CAP).                          | Uses key-target relationships in synthetic data based on known features in real data.                 | Ideal for assessing disclosure risk when attackers know certain fields and may infer others.         | Simple yet effective for evaluating conditional privacy risks.                                       | Limited to categorical data; may require specific key/target selection.                              | 0 to 1                                 | **Higher values preferred (closer to 1)**. <br> **Best (1.0):** Real data is 100% protected from the attack (attacker cannot guess sensitive values). <br> **Worst (0.0):** Real data is vulnerable to attack (attacker can guess every sensitive value).    |\n",
    "| **NewRowSynthesis**           | Assesses privacy by measuring whether each row in the synthetic data is novel, or whether it exactly matches an original row in the real data.    | Calculates row-level matches or minimum distances to identify duplicate or nearly duplicate rows.     | Useful in scenarios where any direct copying of real data into synthetic data poses privacy risks.   | Effective for identifying direct replication risks.                                                  | Limited to row-level exact matches; may overlook nuanced, indirect similarities.                     | 0 to 1                                 | **Higher values preferred (closer to 1)**. <br> **Best (1.0):** All rows in synthetic data are new, with no matches in real data. <br> **Worst (0.0):** Synthetic data contains direct copies of real data rows. |\n",
    "| **Inference Attacks**         | Evaluates re-identification or attribute inference risks, estimating the likelihood that synthetic data allows sensitive attribute inference through statistical methods. Privacy Against Inference describes a set of metrics that calculate the risk of an attacker being able to infer real, sensitive values. We assume that an attacker already possess a few columns of real data; they will combine it with the synthetic data to make educated guesses.    | Employs statistical/ML models to simulate attacks that deduce sensitive information from known fields. | Used in risk analysis when there is concern that synthetic data could reveal sensitive information.  | Provides broad risk assessment by simulating realistic attacks.                                      | Computationally intensive; results vary depending on the models used.                                | Probability scores (0 to 1)           | **Higher values preferred (closer to 1)**. <br> **Best (1.0):** Real data is safe from attack (attacker cannot correctly guess sensitive values). <br> **Worst (0.0):** Real data is vulnerable to attack (attacker can guess every sensitive value). |\n",
    "| **TCAP Score**                | Target Correct Attribution Probability (TCAP) measures the risk of correctly attributing sensitive target values based on known key attributes in synthetic data.           | Computes the probability of matching real key-target pairings using the corresponding synthetic data.  | Applies when specific attributes in real data should remain private.                                | Provides targeted privacy risk assessment using key-target pairings.                                  | Limited to categorical data; continuous data must be binned.                                         | 0 to 1                                 | **Lower values preferred (closer to 0)**. |\n",
    "| **Minimum Nearest-Neighbour** | Measures privacy risk by calculating the closest distance between real and synthetic data points, focusing on potential privacy issues among outlier points in real data. | Computes the minimum distance between real and synthetic data points, optionally filtering outliers.  | Useful where synthetic data should not closely resemble real data, especially protecting outliers.   | Effectively identifies overly close matches in synthetic data.                                       | Sensitive to parameter choices like threshold and outlier settings; assumes ordinal data encoding.   | Normalized distance metric (0 to 1)              | **Higher values preferred**. |\n",
    "| **Sample Overlap Score**      | Estimates the privacy risk by measuring the percentage overlap between random samples of real and synthetic data.                                                            | Calculates overlap between sampled real and synthetic datasets, as unique or non-unique matches.       | Useful for determining the degree to which synthetic data replicates real data patterns on a sample basis. | Offers a flexible approach to measuring data similarity, adjustable via sampling settings.            | Dependent on sampling and seed choices; requires carefully chosen features for accuracy.             | Percentage overlap (0 to 100%)        | **Lower values preferred (closer to 0%)**. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from privacy_report_generator import PrivacyRiskEvaluator\n",
    "\n",
    "privacyRiskEvaluator = PrivacyRiskEvaluator(real_data = processed_data, synthetic_data = generated_data, metadata = metadata, method=synthetic_data_type)\n",
    "privacyRiskEvaluator.run_privacy_realistic()\n",
    "privacyRiskEvaluator.plot_privacy_metrics_realistic(output_path = output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFP Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def privacy_report(input_synth_csv: comp.InputPath('csv'), input_real_csv: comp.InputPath('csv'), input_json:comp.InputPath('json'), output_html: comp.OutputPath('html')) -> NamedTuple('VisualizationOutput', [('mlpipeline_ui_metadata', 'UI_metadata')]):\n",
    "    import synthguard.helper_functions as sd\n",
    "    import json\n",
    "\n",
    "    with open(output_html, \"w\") as f:\n",
    "        f.write(\"<html><body>\")  # Start the HTML document\n",
    "\n",
    "    #Component logic\n",
    "    from synthguard.privacy_report_generator import PrivacyRiskEvaluator\n",
    "    real_data = sd.load_data_csv(input_real_csv)\n",
    "    synthetic_data = sd.load_data_csv(input_synth_csv)\n",
    "    metadata = sd.load_metadata(input_json)\n",
    "    synthetic_data_type = 'realistic'\n",
    "    \n",
    "    \n",
    "    privacyRiskEvaluator = PrivacyRiskEvaluator(real_data = real_data, synthetic_data = synthetic_data, metadata = metadata, method=synthetic_data_type)\n",
    "    privacyRiskEvaluator.run_privacy_realistic()\n",
    "    privacyRiskEvaluator.plot_privacy_metrics_realistic()\n",
    "    privacyRiskEvaluator.save_plot_to_html(output_html)\n",
    "\n",
    "    # Read the HTML content for UI metadata\n",
    "    with open(output_html, 'r') as file:\n",
    "        html_content = file.read()\n",
    "\n",
    "    metadata = {\n",
    "        'outputs': [{\n",
    "            'type': 'web-app',\n",
    "            'storage': 'inline',\n",
    "            'source': html_content,\n",
    "        }]\n",
    "    }\n",
    "\n",
    "    from collections import namedtuple\n",
    "    visualization_output = namedtuple('VisualizationOutput', ['mlpipeline_ui_metadata'])\n",
    "    return visualization_output(json.dumps(metadata))\n",
    "\n",
    "\n",
    "# Compiling funtion into a KFP component\n",
    "privacy_component = comp.create_component_from_func(func = privacy_report, base_image = 'python:3.10', \n",
    "                                                    packages_to_install = sg_package)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name='SDG_example_pipeline_mahmoud', description='')\n",
    "def pipeline(target_utility, target_privacy):\n",
    "\tinput = input_component()\n",
    "\tpreprocess = preprocess_component(input.output)\n",
    "\tgeneration = generation_component(target_utility, target_privacy, input.output, preprocess.output)\n",
    "\tdianostic = diagnostic_component(input.output, generation.output, preprocess.output)\n",
    "\tutility = utility_component(input.output, generation.output, preprocess.output)\n",
    "\tprivacy = privacy_component(input.output, generation.output, preprocess.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Compiler().compile(pipeline, 'LAGO_SDG.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
